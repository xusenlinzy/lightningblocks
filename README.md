<div align="center">

**åŸºäº [`pytorch-lightning`](https://github.com/Lightning-AI/lightning) å’Œ [`transformers`](https://github.com/huggingface/transformers) æ¡†æ¶å®ç°å„ç±» `NLP` ä»»åŠ¡**

</div>

## ğŸ”¨ å®‰è£…

1. æ­å»ºå¥½ `pytorch GPU` æ·±åº¦å­¦ä¹ ç¯å¢ƒ

```bash
conda create -n pytorch python=3.8
conda activate pytorch
conda install pytorch cudatoolkit -c pytorch
```

2. å®‰è£… `lightningnlp`

```bash
pip install lightningnlp
```

3. åœ¨ `https://pytorch-geometric.com/whl/` ä¸­æ‰¾åˆ°ä¸ `torch` ç‰ˆæœ¬å¯¹åº”çš„ `torch_scatter`ï¼Œä¸‹è½½åä½¿ç”¨ `pip` å®‰è£…åˆ°ç¯å¢ƒä¸­ 

```python
import torch
print(torch.__version__)  # 1.12.0
print(torch.version.cuda)  # 11.3
```

```bash
# ä»¥python=3.8, torch=1.12.0, cuda=11.3ä¸ºä¾‹
wget https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.1.0%2Bpt112cu113-cp38-cp38-linux_x86_64.whl
pip install torch_scatter-2.1.0+pt112cu113-cp38-cp38-linux_x86_64.whl
```

æœ¬é¡¹ç›®ä¹Ÿæä¾›äº†[dockerå®‰è£…æ–¹å¼](./docker)

## ğŸ§¾ æ–‡æœ¬åˆ†ç±»

### 1. æ•°æ®æ ¼å¼

<details>
<summary>è®­ç»ƒæ•°æ®ç¤ºä¾‹</summary>

```json
{
  "text": "ä»¥è‰²åˆ—å¤§è§„æ¨¡ç©ºè¢­å¼€å§‹ï¼ä¼Šæœ—å¤šä¸ªå†›äº‹ç›®æ ‡é­é‡æ‰“å‡»ï¼Œèª“è¨€å¯¹ç­‰åå‡»",
  "label": "news_military"
}
```

</details>

### 2. æ¨¡å‹

| æ¨¡å‹                                                        | è®ºæ–‡                                                                                                           | å¤‡æ³¨                              |
|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------|
| [fc](lightningnlp/task/text_classification/fc/model.py)   |                                                                                                              | å…¨è¿æ¥å±‚åˆ†ç±»                          |
| [mdp](lightningnlp/task/text_classification/mdp/model.py) | [Multi-Sample Dropout for Accelerated Training and Better Generalization.](https://arxiv.org/abs/1905.09788) | ä½¿ç”¨ `MultiSampleDropout`ï¼Œç±»ä¼¼äºæ¨¡å‹èåˆ |

<details>
<summary>è®­ç»ƒä»£ç ç¤ºä¾‹</summary>

```python
import os
os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger  # éœ€è¦å®‰è£…wandb
from transformers import BertTokenizerFast

from lightningnlp.callbacks import LoggingCallback
from lightningnlp.task.text_classification import (
    TextClassificationDataModule,
    TextClassificationTransformer,
)

pl.seed_everything(seed=42)
pretrained_model_name_or_path = "hfl/chinese-roberta-wwm-ext"  # é¢„è®­ç»ƒæ¨¡å‹
tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path)

dm = TextClassificationDataModule(
    tokenizer=tokenizer,
    train_batch_size=16,  # è®­ç»ƒé›†batch_size
    validation_batch_size=16,  # éªŒè¯é›†batch_size
    num_workers=16,  # å¤šè¿›ç¨‹åŠ è½½æ•°æ®
    dataset_name="datasets/tnews",  # è®­ç»ƒæ•°æ®æ‰€åœ¨ç›®å½•
    train_file="train.json",  # è®­ç»ƒé›†æ–‡ä»¶å
    validation_file="dev.json",  # éªŒè¯é›†æ–‡ä»¶å
    train_max_length=256,
    cache_dir="datasets/tnews",  # æ•°æ®ç¼“å­˜è·¯å¾„
)

model = TextClassificationTransformer(
    downstream_model_name="fc",  # æ¨¡å‹åç§°
    downstream_model_type="bert",  # é¢„è®­ç»ƒæ¨¡å‹ç±»å‹
    pretrained_model_name_or_path=pretrained_model_name_or_path,
    tokenizer=tokenizer,
    label_map=dm.id2label,
    learning_rate=2e-5,
    output_dir="outputs/tnews/fc",  # æ¨¡å‹ä¿å­˜è·¯å¾„
)

model_ckpt = pl.callbacks.ModelCheckpoint(
    dirpath="outputs/tnews/fc",
    filename="best_model",
    monitor="val_accuracy",
    save_top_k=1,
    mode="max",
)

wandb_logger = WandbLogger(project="Text Classification", name="fc")

trainer = pl.Trainer(
    logger=wandb_logger,
    accelerator="gpu",
    devices=1,
    max_epochs=12,
    val_check_interval=0.5,
    gradient_clip_val=1.0,
    callbacks=[model_ckpt, LoggingCallback()]
)

trainer.fit(model, dm)
```

</details>

### 3. é¢„æµ‹

```python
from lightningnlp.task.text_classification import TextClassificationPipeline

pipeline = TextClassificationPipeline(model_name_or_path="outputs/tnews/fc", model_name="fc", model_type="bert")
text = "ä»¥è‰²åˆ—å¤§è§„æ¨¡ç©ºè¢­å¼€å§‹ï¼ä¼Šæœ—å¤šä¸ªå†›äº‹ç›®æ ‡é­é‡æ‰“å‡»ï¼Œèª“è¨€å¯¹ç­‰åå‡»"
print(pipeline(text))
```

### 4. APPåº”ç”¨
![tc](images/tc.png)


## ğŸ“„ å‘½åå®ä½“è¯†åˆ«

### 1. æ•°æ®æ ¼å¼

<details>
<summary>è®­ç»ƒæ•°æ®ç¤ºä¾‹</summary>

```json
{
  "text": "ç»“æœä¸Šå‘¨å…­ä»–ä»¬ä¸»åœº0ï¼š3æƒ¨è´¥ç»™äº†ä¸­æ¸¸çƒé˜Ÿç“¦æ‹‰å¤šåˆ©å¾·ï¼Œè¿‘7ä¸ªå¤šæœˆä»¥æ¥è¥¿ç”²é¦–æ¬¡è¾“çƒã€‚", 
  "entities": [
    {
      "id": 0, 
      "entity": "ç“¦æ‹‰å¤šåˆ©å¾·", 
      "start_offset": 20, 
      "end_offset": 25, 
      "label": "organization"
    }, 
    {
      "id": 1, 
      "entity": "è¥¿ç”²", 
      "start_offset": 33, 
      "end_offset": 35, 
      "label": "organization"
    }
  ]
}
```
</details>


### 2. æ¨¡å‹


| æ¨¡å‹                                                                                   | è®ºæ–‡                                                                                                                                                                            | å¤‡æ³¨                                                                                                                                            |
|--------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| [softmax](lightningnlp/task/named_entity_recognition/crf/model.py)                   |                                                                                                                                                                               | å…¨è¿æ¥å±‚åºåˆ—æ ‡æ³¨å¹¶ä½¿ç”¨ `BIO` è§£ç                                                                                                                           |
| [crf](lightningnlp/task/named_entity_recognition/crf/model.py)                       | [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers) | å…¨è¿æ¥å±‚+æ¡ä»¶éšæœºåœºï¼Œå¹¶ä½¿ç”¨ `BIO` è§£ç                                                                                                                        |
| [cascade-crf](lightningnlp/task/named_entity_recognition/crf/model.py)               |                                                                                                                                                                               | å…ˆé¢„æµ‹å®ä½“å†é¢„æµ‹å®ä½“ç±»å‹                                                                                                                                  |
| [span](lightningnlp/task/named_entity_recognition/span/model.py)                     |                                                                                                                                                                               | ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆç½‘ç»œé¢„æµ‹å®ä½“èµ·å§‹ä½ç½®                                                                                                                              |
| [global-pointer](lightningnlp/task/named_entity_recognition/global_pointer/model.py) |                                                                                                                                                                               | [GlobalPointerï¼šç”¨ç»Ÿä¸€çš„æ–¹å¼å¤„ç†åµŒå¥—å’ŒéåµŒå¥—NER](https://spaces.ac.cn/archives/8373)ã€[Efficient GlobalPointerï¼šå°‘ç‚¹å‚æ•°ï¼Œå¤šç‚¹æ•ˆæœ](https://spaces.ac.cn/archives/8877) |
| [mrc](lightningnlp/task/named_entity_recognition/mrc/model.py)                       | [A Unified MRC Framework for Named Entity Recognition.](https://aclanthology.org/2020.acl-main.519.pdf)                                                                       | å°†å®ä½“è¯†åˆ«ä»»åŠ¡è½¬æ¢ä¸ºé˜…è¯»ç†è§£é—®é¢˜ï¼Œè¾“å…¥ä¸ºå®ä½“ç±»å‹æ¨¡æ¿+å¥å­ï¼Œé¢„æµ‹å¯¹åº”å®ä½“çš„èµ·å§‹ä½ç½®                                                                                                     |
| [tplinker](lightningnlp/task/named_entity_recognition/tplinker/model.py)             | [TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking.](https://aclanthology.org/2020.coling-main.138.pdf)                            | å°†å®ä½“è¯†åˆ«ä»»åŠ¡è½¬æ¢ä¸ºè¡¨æ ¼å¡«å……é—®é¢˜                                                                                                                              |
| [lear](lightningnlp/task/named_entity_recognition/lear/model.py)                     | [Enhanced Language Representation with Label Knowledge for Span Extraction.](https://aclanthology.org/2021.emnlp-main.379.pdf)                                                | æ”¹è¿› `MRC` æ–¹æ³•æ•ˆç‡é—®é¢˜ï¼Œé‡‡ç”¨æ ‡ç­¾èåˆæœºåˆ¶                                                                                                                      |
| [w2ner](lightningnlp/task/named_entity_recognition/w2ner/model.py)                   | [Unified Named Entity Recognition as Word-Word Relation Classification.](https://arxiv.org/pdf/2112.10070.pdf)                                                                | ç»Ÿä¸€è§£å†³åµŒå¥—å®ä½“ã€ä¸è¿ç»­å®ä½“çš„æŠ½å–é—®é¢˜                                                                                                                           |
| [cnn](lightningnlp/task/named_entity_recognition/cnn/model.py)                       | [An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition.](https://arxiv.org/abs/2208.04534)                                                           | æ”¹è¿› `W2NER` æ–¹æ³•ï¼Œé‡‡ç”¨å·ç§¯ç½‘ç»œæå–å®ä½“å†…éƒ¨tokenä¹‹é—´çš„å…³ç³»                                                                                                          |

<details>
<summary>è®­ç»ƒä»£ç ç¤ºä¾‹</summary>

```python
import os
os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
from transformers import BertTokenizerFast

from lightningnlp.callbacks import LoggingCallback
from lightningnlp.task.named_entity_recognition import (
    CRFNerDataModule,
    NamedEntityRecognitionTransformer,
)

pl.seed_everything(seed=42)
pretrained_model_name_or_path = "hfl/chinese-roberta-wwm-ext"  # é¢„è®­ç»ƒæ¨¡å‹
tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path)

dm = CRFNerDataModule(
    tokenizer=tokenizer,
    train_batch_size=16,  # è®­ç»ƒé›†batch_size
    validation_batch_size=16,  # éªŒè¯é›†batch_size
    num_workers=16,  # å¤šè¿›ç¨‹åŠ è½½æ•°æ®
    dataset_name="xusenlin/cmeee",  # huggingfaceæ•°æ®é›†
    train_max_length=256,
    validation_max_length=256,
    cache_dir="datasets/cmeee",  # æ•°æ®ç¼“å­˜è·¯å¾„
    task_name="cmeee-bert-crf",  # è‡ªå®šä¹‰ä»»åŠ¡åç§°
    is_chinese=True,
)

model = NamedEntityRecognitionTransformer(
    downstream_model_name="crf",  # æ¨¡å‹åç§°
    downstream_model_type="bert",  # é¢„è®­ç»ƒæ¨¡å‹ç±»å‹
    pretrained_model_name_or_path=pretrained_model_name_or_path,
    tokenizer=tokenizer,
    labels=dm.label_list,
    learning_rate=2e-5,
    average="micro",
    output_dir="outputs/cmeee/crf",  # æ¨¡å‹ä¿å­˜è·¯å¾„
)

model_ckpt = pl.callbacks.ModelCheckpoint(
    dirpath="outputs/cmeee/crf",
    filename="best_model",
    monitor="val_f1_micro",
    save_top_k=1,
    mode="max",
)

wandb_logger = WandbLogger(project="Named Entity Recognition", name="cmeee-bert-crf")

trainer = pl.Trainer(
    logger=wandb_logger,
    accelerator="gpu",
    devices=1,
    max_epochs=12,
    val_check_interval=0.5,
    gradient_clip_val=1.0,
    callbacks=[model_ckpt, LoggingCallback()]
)

trainer.fit(model, dm)
```

</details>

### 3. é¢„æµ‹

æœ¬é¡¹ç›®åœ¨ [huggingface](https://huggingface.co/xusenlin/cmeee-global-pointer) ä¸Šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ä½œä¸ºç¤ºä¾‹å¯ä¾›æµ‹è¯•å’Œä½¿ç”¨ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹

```python
from pprint import pprint
from lightningnlp.task.named_entity_recognition import NerPipeline

pipline = NerPipeline(model_name_or_path="xusenlin/cmeee-global-pointer", model_name="global-pointer", model_type="bert")
text = "ç»“æœä¸Šå‘¨å…­ä»–ä»¬ä¸»åœº0ï¼š3æƒ¨è´¥ç»™äº†ä¸­æ¸¸çƒé˜Ÿç“¦æ‹‰å¤šåˆ©å¾·ï¼Œè¿‘7ä¸ªå¤šæœˆä»¥æ¥è¥¿ç”²é¦–æ¬¡è¾“çƒã€‚"
pprint(pipline(text))
```

### 4. APPåº”ç”¨

![ner](./images/ner.png)


## ğŸ”– å®ä½“å…³ç³»æŠ½å–

### 1. æ•°æ®æ ¼å¼

<details>
<summary>è®­ç»ƒæ•°æ®ç¤ºä¾‹</summary>

```json
{
  "text": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯ï¼ˆCharles ArÃ¡nguizï¼‰ï¼Œ1989å¹´4æœˆ17æ—¥å‡ºç”Ÿäºæ™ºåˆ©åœ£åœ°äºšå“¥ï¼Œæ™ºåˆ©èŒä¸šè¶³çƒè¿åŠ¨å‘˜ï¼Œå¸èŒä¸­åœºï¼Œæ•ˆåŠ›äºå¾·å›½è¶³çƒç”²çº§è”èµ›å‹’æ²ƒåº“æ£®è¶³çƒä¿±ä¹éƒ¨", 
  "spo_list": [
    {
      "predicate": "å‡ºç”Ÿåœ°", 
      "object_type": "åœ°ç‚¹", 
      "subject_type": "äººç‰©", 
      "object": "åœ£åœ°äºšå“¥", 
      "subject": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯"
    }, 
    {
      "predicate": "å‡ºç”Ÿæ—¥æœŸ", 
      "object_type": "Date", 
      "subject_type": "äººç‰©", 
      "object": "1989å¹´4æœˆ17æ—¥",
      "subject": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯"
    }
  ]
}
```

</details>


### 2. æ¨¡å‹

| æ¨¡å‹                                                                  | è®ºæ–‡                                                                                                                                                 | å¤‡æ³¨                                                                  |
|---------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------|
| [casrel](lightningnlp/task/relation_extraction/casrel/model.py)     | [A Novel Cascade Binary Tagging Framework for Relational Triple Extraction.](https://aclanthology.org/2020.acl-main.136.pdf)                       | ä¸¤é˜¶æ®µå…³ç³»æŠ½å–ï¼Œå…ˆæŠ½å–å‡ºå¥å­ä¸­çš„ä¸»è¯­ï¼Œå†é€šè¿‡æŒ‡é’ˆç½‘ç»œæŠ½å–å‡ºä¸»è¯­å¯¹åº”çš„å…³ç³»å’Œå®¾è¯­                             |
| [tplinker](lightningnlp/task/relation_extraction/tplinker/model.py) | [TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking.](https://aclanthology.org/2020.coling-main.138.pdf) | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬æ¢ä¸ºä¸»è¯­-å®¾è¯­çš„é¦–å°¾è¿æ¥é—®é¢˜                                              |
| [spn](lightningnlp/task/relation_extraction/spn/model.py)           | [Joint Entity and Relation Extraction with Set Prediction Networks.](http://xxx.itp.ac.cn/pdf/2011.01675v2)                                        | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬ä¸ºä¸ºä¸‰å…ƒç»„çš„é›†åˆé¢„æµ‹é—®é¢˜ï¼Œé‡‡ç”¨ `Encoder-Decoder` æ¡†æ¶                        |
| [prgc](lightningnlp/task/relation_extraction/prgc/model.py)         | [PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction.](https://aclanthology.org/2021.acl-long.486.pdf)     | å…ˆæŠ½å–å¥å­çš„æ½œåœ¨å…³ç³»ç±»å‹ï¼Œç„¶åå¯¹äºç»™å®šå…³ç³»æŠ½å–å‡ºå¯¹åº”çš„ä¸»è¯­-å®¾è¯­å¯¹ï¼Œæœ€åé€šè¿‡å…¨å±€å¯¹é½æ¨¡å—è¿‡æ»¤                      |
| [pfn](lightningnlp/task/relation_extraction/pfn/model.py)           | [A Partition Filter Network for Joint Entity and Relation Extraction.](https://aclanthology.org/2021.emnlp-main.17.pdf)                            | é‡‡ç”¨ç±»ä¼¼  `LSTM`  çš„åˆ†åŒºè¿‡æ»¤æœºåˆ¶ï¼Œå°†éšè—å±‚ä¿¡æ¯åˆ†æˆå®ä½“è¯†åˆ«ã€å…³ç³»è¯†åˆ«å’Œå…±äº«ä¸‰éƒ¨åˆ†ï¼Œå¯¹ä¸ä¸åŒçš„ä»»åŠ¡åˆ©ç”¨ä¸åŒçš„ä¿¡æ¯        |
| [grte](lightningnlp/task/relation_extraction/grte/model.py)         | [A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling.](https://aclanthology.org/2021.emnlp-main.208.pdf)     | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬æ¢ä¸ºå•è¯å¯¹çš„åˆ†ç±»é—®é¢˜ï¼ŒåŸºäºå…¨å±€ç‰¹å¾æŠ½å–æ¨¡å—å¾ªç¯ä¼˜åŒ–å•è¯å¯¹çš„å‘é‡è¡¨ç¤º                           |
| [gplinker](lightningnlp/task/relation_extraction/gplinker/model.py) |                                                                                                                                                    | [GPLinkerï¼šåŸºäºGlobalPointerçš„å®ä½“å…³ç³»è”åˆæŠ½å–](https://kexue.fm/archives/8888) |


<details>
<summary>è®­ç»ƒä»£ç ç¤ºä¾‹</summary>

```python
import os
os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
from transformers import BertTokenizerFast

from lightningnlp.callbacks import LoggingCallback
from lightningnlp.task.relation_extraction import (
    GPLinkerDataModule,
    RelationExtractionTransformer,
)

pl.seed_everything(seed=42)
pretrained_model_name_or_path = "hfl/chinese-roberta-wwm-ext"  # é¢„è®­ç»ƒæ¨¡å‹
tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path)

dm = GPLinkerDataModule(
    tokenizer=tokenizer,
    train_batch_size=16,  # è®­ç»ƒé›†batch_size
    validation_batch_size=16,  # éªŒè¯é›†batch_size
    num_workers=16,  # å¤šè¿›ç¨‹åŠ è½½æ•°æ®
    dataset_name="xusenlin/duie",  # huggingfaceæ•°æ®é›†
    train_max_length=256,
    validation_max_length=256,
    cache_dir="datasets/duie",  # æ•°æ®ç¼“å­˜è·¯å¾„
    task_name="duie-bert-gplinker",  # è‡ªå®šä¹‰ä»»åŠ¡åç§°
    is_chinese=True,
)

model = RelationExtractionTransformer(
    downstream_model_name="gplinker",  # æ¨¡å‹åç§°
    downstream_model_type="bert",  # é¢„è®­ç»ƒæ¨¡å‹ç±»å‹
    pretrained_model_name_or_path=pretrained_model_name_or_path,
    tokenizer=tokenizer,
    predicates=dm.predicate_list,
    learning_rate=2e-5,
    average="micro",
    output_dir="outputs/duie/gplinker",  # æ¨¡å‹ä¿å­˜è·¯å¾„
)

model_ckpt = pl.callbacks.ModelCheckpoint(
    dirpath="outputs/duie/gplinker",
    filename="best_model",
    monitor="val_f1_micro",
    save_top_k=1,
    mode="max",
)

wandb_logger = WandbLogger(project="Relation Extraction", name="duie-bert-gplinker")

trainer = pl.Trainer(
    logger=wandb_logger,
    accelerator="gpu",
    devices=1,
    max_epochs=12,
    val_check_interval=0.5,
    gradient_clip_val=1.0,
    callbacks=[model_ckpt, LoggingCallback()]
)

trainer.fit(model, dm)
```

</details>

### 3. é¢„æµ‹

æœ¬é¡¹ç›®åœ¨ [huggingface](https://huggingface.co/xusenlin/duie-gplinker) ä¸Šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ä½œä¸ºç¤ºä¾‹å¯ä¾›æµ‹è¯•å’Œä½¿ç”¨ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹

```python
from pprint import pprint
from lightningnlp.task.relation_extraction import RelationExtractionPipeline

pipline = RelationExtractionPipeline(model_name_or_path="xusenlin/duie-gplinker", model_name="gplinker", model_type="bert")
text = "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯ï¼ˆCharles ArÃ¡nguizï¼‰ï¼Œ1989å¹´4æœˆ17æ—¥å‡ºç”Ÿäºæ™ºåˆ©åœ£åœ°äºšå“¥ï¼Œæ™ºåˆ©èŒä¸šè¶³çƒè¿åŠ¨å‘˜ï¼Œå¸èŒä¸­åœºï¼Œæ•ˆåŠ›äºå¾·å›½è¶³çƒç”²çº§è”èµ›å‹’æ²ƒåº“æ£®è¶³çƒä¿±ä¹éƒ¨ã€‚"
pprint(pipline(text))
```

### 4. APPåº”ç”¨

![re](./images/re.png)


## ğŸ­ é€šç”¨ä¿¡æ¯æŠ½å–

+ [UIE(Universal Information Extraction)](https://arxiv.org/pdf/2203.12277.pdf)ï¼šYaojie Luç­‰äººåœ¨ACL-2022ä¸­æå‡ºäº†é€šç”¨ä¿¡æ¯æŠ½å–ç»Ÿä¸€æ¡†æ¶ `UIE`ã€‚

+ è¯¥æ¡†æ¶å®ç°äº†å®ä½“æŠ½å–ã€å…³ç³»æŠ½å–ã€äº‹ä»¶æŠ½å–ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡çš„ç»Ÿä¸€å»ºæ¨¡ï¼Œå¹¶ä½¿å¾—ä¸åŒä»»åŠ¡é—´å…·å¤‡è‰¯å¥½çš„è¿ç§»å’Œæ³›åŒ–èƒ½åŠ›ã€‚

+ ä¸ºäº†æ–¹ä¾¿å¤§å®¶ä½¿ç”¨ `UIE` çš„å¼ºå¤§èƒ½åŠ›ï¼Œ[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)å€Ÿé‰´è¯¥è®ºæ–‡çš„æ–¹æ³•ï¼ŒåŸºäº `ERNIE 3.0` çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒå¹¶å¼€æºäº†é¦–ä¸ªä¸­æ–‡é€šç”¨ä¿¡æ¯æŠ½å–æ¨¡å‹ `UIE`ã€‚

+ è¯¥æ¨¡å‹å¯ä»¥æ”¯æŒä¸é™å®šè¡Œä¸šé¢†åŸŸå’ŒæŠ½å–ç›®æ ‡çš„å…³é”®ä¿¡æ¯æŠ½å–ï¼Œå®ç°é›¶æ ·æœ¬å¿«é€Ÿå†·å¯åŠ¨ï¼Œå¹¶å…·å¤‡ä¼˜ç§€çš„å°æ ·æœ¬å¾®è°ƒèƒ½åŠ›ï¼Œå¿«é€Ÿé€‚é…ç‰¹å®šçš„æŠ½å–ç›®æ ‡ã€‚

![uie](./images/uie.png)

<details>
<summary>ğŸ‘‰ å‘½åå®ä½“è¯†åˆ«</summary>

```python
from pprint import pprint
from lightningnlp.task.uie import UIEPredictor

# å®ä½“è¯†åˆ«
schema = ['æ—¶é—´', 'é€‰æ‰‹', 'èµ›äº‹åç§°'] 
# uie-baseæ¨¡å‹å·²ä¸Šä¼ è‡³huggingfaceï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œå…¶ä»–æ¨¡å‹åªéœ€æä¾›æ¨¡å‹åç§°å°†è‡ªåŠ¨è¿›è¡Œè½¬æ¢
uie = UIEPredictor("xusenlin/uie-base", schema=schema)
pprint(uie("2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼")) # Better print results using pprint
```
è¾“å‡ºï¼š
```text
[{'æ—¶é—´': [{'end': 6,
          'probability': 0.9857378532924486,
          'start': 0,
          'text': '2æœˆ8æ—¥ä¸Šåˆ'}],
  'èµ›äº‹åç§°': [{'end': 23,
            'probability': 0.8503089953268272,
            'start': 6,
            'text': 'åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›'}],
  'é€‰æ‰‹': [{'end': 31,
          'probability': 0.8981548639781138,
          'start': 28,
          'text': 'è°·çˆ±å‡Œ'}]}]
```
</details>

<details>
<summary>ğŸ‘‰ å®ä½“å…³ç³»æŠ½å–</summary>

```python
from pprint import pprint
from lightningnlp.task.uie import UIEPredictor

# å…³ç³»æŠ½å–
schema = {'ç«èµ›åç§°': ['ä¸»åŠæ–¹', 'æ‰¿åŠæ–¹', 'å·²ä¸¾åŠæ¬¡æ•°']}
# uie-baseæ¨¡å‹å·²ä¸Šä¼ è‡³huggingfaceï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œå…¶ä»–æ¨¡å‹åªéœ€æä¾›æ¨¡å‹åç§°å°†è‡ªåŠ¨è¿›è¡Œè½¬æ¢
uie = UIEPredictor("xusenlin/uie-base", schema=schema)
pprint(uie("2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›ç”±ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè”åˆä¸»åŠï¼Œç™¾åº¦å…¬å¸ã€ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼šæ‰¿åŠï¼Œå·²è¿ç»­ä¸¾åŠ4å±Šï¼Œæˆä¸ºå…¨çƒæœ€çƒ­é—¨çš„ä¸­æ–‡NLPèµ›äº‹ä¹‹ä¸€ã€‚")) # Better print results using pprint
```
è¾“å‡ºï¼š
```text
[{'ç«èµ›åç§°': [{'end': 13,
            'probability': 0.7825402622754041,
            'relations': {'ä¸»åŠæ–¹': [{'end': 22,
                                  'probability': 0.8421710521379353,
                                  'start': 14,
                                  'text': 'ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼š'},
                                  {'end': 30,
                                  'probability': 0.7580801847701935,
                                  'start': 23,
                                  'text': 'ä¸­å›½è®¡ç®—æœºå­¦ä¼š'}],
                          'å·²ä¸¾åŠæ¬¡æ•°': [{'end': 82,
                                    'probability': 0.4671295049136148,
                                    'start': 80,
                                    'text': '4å±Š'}],
                          'æ‰¿åŠæ–¹': [{'end': 39,
                                  'probability': 0.8292706618236352,
                                  'start': 35,
                                  'text': 'ç™¾åº¦å…¬å¸'},
                                  {'end': 72,
                                  'probability': 0.6193477885474685,
                                  'start': 56,
                                  'text': 'ä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼š'},
                                  {'end': 55,
                                  'probability': 0.7000497331473241,
                                  'start': 40,
                                  'text': 'ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼š'}]},
            'start': 0,
            'text': '2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›'}]}]
```
</details>


<details>
<summary>ğŸ‘‰  äº‹ä»¶æŠ½å–</summary>

```python
from pprint import pprint
from lightningnlp.task.uie import UIEPredictor

# äº‹ä»¶æŠ½å–
schema = {"åœ°éœ‡è§¦å‘è¯": ["åœ°éœ‡å¼ºåº¦", "æ—¶é—´", "éœ‡ä¸­ä½ç½®", "éœ‡æºæ·±åº¦"]}
# uie-baseæ¨¡å‹å·²ä¸Šä¼ è‡³huggingfaceï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œå…¶ä»–æ¨¡å‹åªéœ€æä¾›æ¨¡å‹åç§°å°†è‡ªåŠ¨è¿›è¡Œè½¬æ¢
uie = UIEPredictor("xusenlin/uie-base", schema=schema)
pprint(uie("ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®šï¼š5æœˆ16æ—¥06æ—¶08åˆ†åœ¨äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)å‘ç”Ÿ3.5çº§åœ°éœ‡ï¼Œéœ‡æºæ·±åº¦10åƒç±³ã€‚")) # Better print results using pprint
```
è¾“å‡ºï¼š
```text
[{'åœ°éœ‡è§¦å‘è¯': {'end': 58,
            'probability': 0.9977425932884216,
            'relation': {'åœ°éœ‡å¼ºåº¦': [{'end': 56,
                                   'probability': 0.9980800747871399,
                                   'start': 52,
                                   'text': '3.5çº§'}],
                         'æ—¶é—´': [{'end': 22,
                                 'probability': 0.9853301644325256,
                                 'start': 11,
                                 'text': '5æœˆ16æ—¥06æ—¶08åˆ†'}],
                         'éœ‡ä¸­ä½ç½®': [{'end': 50,
                                   'probability': 0.7874020934104919,
                                   'start': 23,
                                   'text': 'äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)'}],
                         'éœ‡æºæ·±åº¦': [{'end': 67,
                                   'probability': 0.9937973618507385,
                                   'start': 63,
                                   'text': '10åƒç±³'}]},
            'start': 56,
            'text': 'åœ°éœ‡'}}]
```
</details>

<details>
<summary>ğŸ‘‰ è¯„è®ºè§‚ç‚¹æŠ½å–</summary>

```python
from pprint import pprint
from lightningnlp.task.uie import UIEPredictor

# äº‹ä»¶æŠ½å–
schema = {'è¯„ä»·ç»´åº¦': ['è§‚ç‚¹è¯', 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]']}
# uie-baseæ¨¡å‹å·²ä¸Šä¼ è‡³huggingfaceï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œå…¶ä»–æ¨¡å‹åªéœ€æä¾›æ¨¡å‹åç§°å°†è‡ªåŠ¨è¿›è¡Œè½¬æ¢
uie = UIEPredictor("xusenlin/uie-base", schema=schema)
pprint(uie("åº—é¢å¹²å‡€ï¼Œå¾ˆæ¸…é™ï¼ŒæœåŠ¡å‘˜æœåŠ¡çƒ­æƒ…ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œå‘ç°æ”¶é“¶å°æœ‰æ’é˜Ÿ")) # Better print results using pprint
```
è¾“å‡ºï¼š
```text
[{'è¯„ä»·ç»´åº¦': [{'end': 20,
            'probability': 0.9817040258681473,
            'relations': {'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': [{'probability': 0.9966142505350533,
                                          'text': 'æ­£å‘'}],
                          'è§‚ç‚¹è¯': [{'end': 22,
                                  'probability': 0.957396472711558,
                                  'start': 21,
                                  'text': 'é«˜'}]},
            'start': 17,
            'text': 'æ€§ä»·æ¯”'},
          {'end': 2,
            'probability': 0.9696849569741168,
            'relations': {'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': [{'probability': 0.9982153274927796,
                                          'text': 'æ­£å‘'}],
                          'è§‚ç‚¹è¯': [{'end': 4,
                                  'probability': 0.9945318044652538,
                                  'start': 2,
                                  'text': 'å¹²å‡€'}]},
            'start': 0,
            'text': 'åº—é¢'}]}]
```
</details>


<details>
<summary>ğŸ‘‰ æƒ…æ„Ÿåˆ†ç±»</summary>


```python
from pprint import pprint
from lightningnlp.task.uie import UIEPredictor

# äº‹ä»¶æŠ½å–
schema = 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]'
# uie-baseæ¨¡å‹å·²ä¸Šä¼ è‡³huggingfaceï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œå…¶ä»–æ¨¡å‹åªéœ€æä¾›æ¨¡å‹åç§°å°†è‡ªåŠ¨è¿›è¡Œè½¬æ¢
uie = UIEPredictor("xusenlin/uie-base", schema=schema)
pprint(uie("è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢")) # Better print results using pprint
```
è¾“å‡ºï¼š
```text
[{'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': {'end': 0,
                  'probability': 0.9990023970603943,
                  'start': 0,
                  'text': 'æ­£å‘'}}]
```
</details>


## Citation
å¦‚æœ `LightningNLP` å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨

```text
@misc{=lightningnlp,
    title={LightningNLP: An Easy-to-use NLP Library},
    author={senlin xu},
    howpublished = {\url{https://github.com/xusenlinzy/lightningblocks}},
    year={2022}
}
```

## Acknowledge

æˆ‘ä»¬å€Ÿé‰´äº†[`Lightning-transformers`](https://github.com/Lightning-AI/lightning-transformers) å…³äºæ¨¡å‹ä½¿ç”¨çš„ä¼˜ç§€è®¾è®¡ï¼Œåœ¨æ­¤å¯¹`Lightning-transformers` ä½œè€…åŠå…¶å¼€æºç¤¾åŒºè¡¨ç¤ºæ„Ÿè°¢ã€‚